{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Char 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "2kRE7ERryaN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Yig4arTnyYJn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "JrolNJEhzJYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Datasets**"
      ],
      "metadata": {
        "id": "Ub6qOv6oxuxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Mnist Dataset"
      ],
      "metadata": {
        "id": "s_kTGkKFyMgO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4wDPIMWxW8L"
      },
      "outputs": [],
      "source": [
        "def load_mnist_dataset():\n",
        "\n",
        "  # load data from tensorflow framework\n",
        "  ((trainData, trainLabels), (testData, testLabels)) = mnist.load_data() \n",
        "\n",
        "  # Stacking train data and test data to form single array named data\n",
        "  data = np.vstack([trainData, testData]) \n",
        "\n",
        "  # Vertical stacking labels of train and test set\n",
        "  labels = np.hstack([trainLabels, testLabels]) \n",
        "\n",
        "  # return a 2-tuple of the MNIST data and labels\n",
        "  return (data, labels)\n",
        "  import cv2 \n",
        "  print(\"hrlods djhds \")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">A-Z  Dataset (**CSV**)"
      ],
      "metadata": {
        "id": "J32jv844y2yH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_az_dataset_csv(url):\n",
        "\n",
        "  # List for storing data\n",
        "  data = []\n",
        "  \n",
        "  # List for storing labels\n",
        "  labels = []\n",
        "  \n",
        "  for row in open(url): #Openfile and start reading each row\n",
        "    #Split the row at every comma\n",
        "    row = row.split(\",\")\n",
        "    \n",
        "    #row[0] contains label\n",
        "    label = int(row[0])\n",
        "    \n",
        "    #Other all collumns contains pixel values make a saperate array for that\n",
        "    image = np.array([int(x) for x in row[1:]], dtype=\"uint8\")\n",
        "    \n",
        "    #Reshaping image to 28 x 28 pixels\n",
        "    image = image.reshape((28, 28))\n",
        "    \n",
        "    #append image to data\n",
        "    data.append(image)\n",
        "    \n",
        "    #append label to labels\n",
        "    labels.append(label)\n",
        "    \n",
        "  #Converting data to numpy array of type float32\n",
        "  data = np.array(data, dtype='float32')\n",
        "  \n",
        "  #Converting labels to type int\n",
        "  labels = np.array(labels, dtype=\"int\")\n",
        "  \n",
        "  return (data, labels)"
      ],
      "metadata": {
        "id": "07FkfoJ9zEhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Characters Dataset (**Images**)"
      ],
      "metadata": {
        "id": "jbfqXELJzbfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset_img(url):\n",
        "  \n",
        "  # List for storing data\n",
        "  data=[]\n",
        "\n",
        "  # List for storing labels\n",
        "  labels=[]\n",
        "\n",
        "  # List of images in directory\n",
        "  imgList = sorted(os.listdir(url))\n",
        "\n",
        "  for i in range(36):  \n",
        "    for j in range(55):\n",
        "        # Processing the image\n",
        "        img = cv2.imread(url+imgList.pop(0),0)\n",
        "        img = cv2.resize(img,(28,28))\n",
        "        # Invert the image for better processing\n",
        "        img = cv2.bitwise_not(img)\n",
        "        \n",
        "        # Append the image in data list\n",
        "        data.append(img)\n",
        "        # Append image name in lable list\n",
        "        labels.append(i)\n",
        "\n",
        "  return (np.array(data),np.array(labels))"
      ],
      "metadata": {
        "id": "b3hoQFp_zvQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ug9znIa4I7Db"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "eBe3WwAsCBTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number Data\n",
        "Ndata,Nlabel = load_mnist_dataset()\n",
        "# Alphabet Data\n",
        "Adata,Alabel = load_az_dataset_csv(\"/content/drive/MyDrive/Character Recognition/A_Z Handwritten Data.csv\")\n",
        "# Characters Data\n",
        "Cdata,Clabel = load_dataset_img(\"/content/drive/MyDrive/Character Recognition/Chars/\")"
      ],
      "metadata": {
        "id": "YAWGp7G1CDQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13bb8fc3-ccb7-443c-b0de-a9293666898b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "b8_QQX6pJAIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing and Combining"
      ],
      "metadata": {
        "id": "3dUhMrcgB3sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the MNIST dataset occupies the labels 0-9, so let's add 10 to every A-Z label to ensure the A-Z characters are not incorrectly labeled \n",
        "Alabel += 10\n",
        "\n",
        "#Combaining the data\n",
        "data = np.vstack([Ndata,Adata,Cdata])\n",
        "data = np.array(data, dtype=\"float32\") #convert from unit8 to float32\n",
        "labels = np.hstack([Nlabel,Alabel,Clabel])\n",
        "\n",
        "# add a channel dimension to every image in the dataset and scale the\n",
        "data = np.expand_dims(data, axis=-1)\n",
        "# pixel intensities of the images from [0, 255] down to [0, 1]\n",
        "data /= 255.0\n"
      ],
      "metadata": {
        "id": "Q--VutQwB2vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "3vpU_O4JJE6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating and Compiling The Model"
      ],
      "metadata": {
        "id": "4Wk7Ss3SHdhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=60,kernel_size=(5,5),input_shape=data.shape[1:],activation=\"relu\"))\n",
        "model.add(keras.layers.Conv2D(filters=60,kernel_size=(5,5),input_shape=data.shape[1:],activation=\"relu\"))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=30,kernel_size=(3,3),activation=\"relu\"))\n",
        "model.add(keras.layers.Conv2D(filters=30,kernel_size=(3,3),activation=\"relu\"))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(500,activation=\"relu\"))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(36,activation=\"softmax\"))\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(data,labels,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSr9g9otHsvO",
        "outputId": "9c7385f6-fa49-4e84-f59a-0bb44a960e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "13889/13889 [==============================] - 2699s 194ms/step - loss: 0.3272 - accuracy: 0.9049\n",
            "Epoch 2/10\n",
            "13889/13889 [==============================] - 2690s 194ms/step - loss: 0.1929 - accuracy: 0.9438\n",
            "Epoch 3/10\n",
            "13889/13889 [==============================] - 2718s 196ms/step - loss: 0.1744 - accuracy: 0.9491\n",
            "Epoch 4/10\n",
            "13889/13889 [==============================] - 2686s 193ms/step - loss: 0.1670 - accuracy: 0.9523\n",
            "Epoch 5/10\n",
            "13889/13889 [==============================] - 2667s 192ms/step - loss: 0.1664 - accuracy: 0.9529\n",
            "Epoch 6/10\n",
            "13889/13889 [==============================] - 2663s 192ms/step - loss: 0.1638 - accuracy: 0.9538\n",
            "Epoch 7/10\n",
            "13889/13889 [==============================] - 2709s 195ms/step - loss: 0.1620 - accuracy: 0.9544\n",
            "Epoch 8/10\n",
            "13889/13889 [==============================] - 2768s 199ms/step - loss: 0.1646 - accuracy: 0.9541\n",
            "Epoch 9/10\n",
            " 3778/13889 [=======>......................] - ETA: 35:00 - loss: 0.1638 - accuracy: 0.9538"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "YOJSvonRRNOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Wapper Functions"
      ],
      "metadata": {
        "id": "-RmVyIOaNIP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Calculate the predicted value"
      ],
      "metadata": {
        "id": "4ygFNsLNNU4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z'}\n",
        "def predictChar(m,fimg):\n",
        "  a = m.predict(fimg)\n",
        "  n = np.argmax(a)\n",
        "  p = a[0][n]*100/a.sum()\n",
        "  return {\"Character\":chars[n],\n",
        "          \"Type\":type(chars[n]),\n",
        "          \"Accuracy\":p/100\n",
        "          }"
      ],
      "metadata": {
        "id": "dWY7pdFSNOpB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Image Processing Function"
      ],
      "metadata": {
        "id": "OXiKY1ICNdxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def processIMG(path):\n",
        "  img = cv2.imread(path,0)\n",
        "  img = cv2.resize(img,(28,28))\n",
        "  img = cv2.bitwise_not(img)\n",
        "  img = np.array(img, dtype=\"float32\")\n",
        "  img = np.expand_dims(img, axis=-1)\n",
        "  img /= 255.0\n",
        "  return img"
      ],
      "metadata": {
        "id": "EdJc4j0ENmL0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Combine Both Wapper Funtions"
      ],
      "metadata": {
        "id": "PipM2jM5BHgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predictImg(m,path,show=0):\n",
        "  img = processIMG(path)\n",
        "  if(show == 1):\n",
        "    plt.imshow(img.reshape(28,28),cmap='gray')\n",
        "  return predictChar(m,img.reshape(1,28,28))"
      ],
      "metadata": {
        "id": "Kg9GP_3j_77W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "Jc3n10HtRJOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "z9WYuoJ3Mt5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "I6tmm-IKRFtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the Model\n",
        "# i1 = processIMG(\"/content/drive/MyDrive/Character Recognition/8.png\")\n",
        "# plt.matshow(i1.reshape(28,28))\n",
        "# predictChar(model,i1.reshape(1,28,28))\n",
        "predictImg(model,\"/content/drive/MyDrive/Character Recognition/a.png\",1)"
      ],
      "metadata": {
        "id": "okWzzr5ZdrFF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8a14af4e-ae44-4a9b-d749-068d82e80f65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 1.0, 'Character': 'A', 'Type': str}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQn0lEQVR4nO3dfYwVVZrH8d8j2oDtqLhkCSKuMiHGkbiwovGFbDDGl0UTnD9UiNlg1ixjfMmga7LG/UMTQzSblXX/GmWCGcbMasaI2iGY0TXDojEhoGF5UxRN64BIg2hEkTTgs390YRrtek57695blz7fT9Lp7nr63Huo7h9V9546dczdBWDkO6HuDgBoD8IOZIKwA5kg7EAmCDuQiRPb+WRmxlv/QIu5uw21vdKR3cyuM7NtZrbdzB6o8lgAWssaHWc3s1GS3pd0taQdktZJmu/uW4M2HNmBFmvFkf0SSdvd/SN375f0nKS5FR4PQAtVCfskSX8Z9P2OYtsxzGyhma03s/UVngtARS1/g87dl0paKnEaD9SpypF9p6TJg74/q9gGoANVCfs6SVPN7Fwz65I0T1JPc7oFoNkaPo1398NmdrekP0kaJelpd9/StJ4BaKqGh94aejJeswMt15KLagAcPwg7kAnCDmSCsAOZIOxAJgg7kIm2zmfPVVdXV1g/dOhQWB81alRYj4ZPTzgh/v/88OHDYf3EE+M/kVTfR48eXVrr7+8P26b6nho2jtqn/t0jEUd2IBOEHcgEYQcyQdiBTBB2IBOEHcgEs97awGzISUjfSw1vpX5H3333XcNtU1J9Tz1+1D7qt5QeeqvSPtX2eMasNyBzhB3IBGEHMkHYgUwQdiAThB3IBGEHMsEU1yZIjZOn6pdddllYv//++8P6tGnTSmvd3d1h29T029Q01Pfffz+s33TTTaW1Tz/9NGxbdYorjsWRHcgEYQcyQdiBTBB2IBOEHcgEYQcyQdiBTDCfvQnGjh0b1u+4446w/tBDD4X16HbMUnyr6dQtkw8cOBDWTznllLCemhf+xRdflNbuuuuusO3KlSsrPfdInrMeKZvPXumiGjPrlbRf0hFJh919ZpXHA9A6zbiC7kp339uExwHQQrxmBzJRNewu6VUze9vMFg71A2a20MzWm9n6is8FoIKqp/Gz3H2nmf21pNfM7D13XzP4B9x9qaSl0sh9gw44HlQ6srv7zuJzn6QXJV3SjE4BaL6Gw25m3Wb2s6NfS7pG0uZmdQxAczU8zm5mUzRwNJcGXg78t7svTrRp2Wl8au5zatnjI0eONPz4t912W9h2yZIlYT3lrbfeCuvPPfdcaa23tzdsu2fPnrA+efLksH7fffeF9SuvvLK0tndvPIhz/fXXh/VNmzaF9Ujq9308j9E3fZzd3T+S9LcN9whAWzH0BmSCsAOZIOxAJgg7kAnCDmRixExxTQ29pZYeTrU/77zzSmsvvfRS2HbChAlh/cknnwzrjzzySFiPpqlWGVKU0rdrPvfcc8N6T09Pae38888P227eHF+2Ed2mWpK2b99eWkvtl+MZSzYDmSPsQCYIO5AJwg5kgrADmSDsQCYIO5CJETPOnhpHT0mNNz/66KOltXvuuSdsu2XLlrB+ww03hPW+vr6wHvW96u83NdXzpJNOCusXX3xxaW3VqlVh29Ry0itWrAjr0e8lusW1dHwvB804O5A5wg5kgrADmSDsQCYIO5AJwg5kgrADmchmnD11K+nu7u6w/uabb5bWpk6dGrZdsGBBWE+NF6eWXY7+7VV/v6n9lnr8qH7LLbeEbZctWxbWU31btGhRae2pp54K247EW0lzZAcyQdiBTBB2IBOEHcgEYQcyQdiBTBB2IBMjZpz9xBPjBWlTY9WXX355WI/mXn/44Ydh27lz54b1nTt3hvXUXPsqY8JVf/9V7tefeu7Vq1eH9SuuuCKsv/rqq6W1W2+9NWz71VdfhfXU31PVv8cqGh5nN7OnzazPzDYP2naGmb1mZh8Un8c1s7MAmm84p/G/k3TdD7Y9IOl1d58q6fXiewAdLBl2d18jad8PNs+VtLz4ermkG5vcLwBNFr+wKDfB3XcVX38mqXQxMzNbKGlhg88DoEkaDfv33N2jN97cfamkpVJr36ADEGt06G23mU2UpOJzfPtTALVrNOw9ko7O21wg6eXmdAdAqyRP483sWUmzJY03sx2SHpL0mKQ/mtntkj6WdHMrOzkcqfW2x4wZE9bnzZsX1kePHl1a2717d9j2m2++CespqX9bdO/2VNtWX2cRzTk/dOhQ2Pbxxx8P6zNmzGi4Pm3atLDtmjVrwnpqLn1qv0ftW7V2fDLs7j6/pHRVk/sCoIW4XBbIBGEHMkHYgUwQdiAThB3IROUr6DpFNDQmSffee29Yv/POO8N6NI30qqvigYm1a9eG9W3btoX11BTarVu3ltbee++9sG1qKueBAwcq1aOhvUsvvTRsG92+W5I2btwY1qPHv/rqq8O2b7zxRlhv9VLYrcCRHcgEYQcyQdiBTBB2IBOEHcgEYQcyQdiBTIyYcfbUdMnULY9beUvkKVOmhPVzzjknrFdZNjk1npvqe39/f1ivMl6cujbixRdfDOvjxsU3NY6miqb2eWq/pP5eUtp5C/ejOLIDmSDsQCYIO5AJwg5kgrADmSDsQCYIO5CJETPOnhr33Lfvh8vVHSs17tnXV74OxjPPPBO2Td0a+KyzzgrrEydODOunnnpqaa27uztse+aZZzb82MMR/V5S10bcfHN8h/LU7yy6BiD1O0ktuZxqn/p7ZJwdQMsQdiAThB3IBGEHMkHYgUwQdiAThB3IxIgZZ0+NW6buj54aN123bl1pbfHixWHbr7/+OqynxmS7urrCerRkczQPX5JOO+20sH766aeH9UmTJoX1Cy+8sLQ2Z86csO3q1avD+jXXXBPWL7rootJa1SWXU/u1jvvCpySP7Gb2tJn1mdnmQdseNrOdZrah+Ih/awBqN5zT+N9Jum6I7f/p7tOLj1XN7RaAZkuG3d3XSIqvNQXQ8aq8QXe3mW0sTvNLbwZmZgvNbL2Zra/wXAAqajTsv5H0c0nTJe2S9HjZD7r7Unef6e4zG3wuAE3QUNjdfbe7H3H37yT9VtIlze0WgGZrKOxmNnjO5S8lbS77WQCdITnObmbPSpotabyZ7ZD0kKTZZjZdkkvqlfSrFvZxWA4fPhzWzz777EqP39vbW1r79ttvw7apawBSY7oHDx4M69G88NRjf/nll2H9k08+CeubNm0K66+88kpp7Yknngjbpsaqr7322rAe/dv3798ftq26zkBqv9cxnz0ZdnefP8TmZS3oC4AW4nJZIBOEHcgEYQcyQdiBTBB2IBMjZorrmDFjwnpq2eTUlMfPP//8J/fpqFYPs0RDb3UM8QwW3ZI5dSvpk08+OayPHz++4edODRmmhv2qLoWdmiLbChzZgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IxIgZZ0+Ne6aWRU61P3DgwE/u01FVx7rrHCtPPXeq3t/fX1pLLYs8bdq0sD5uXOnd0JLPnZq6W3UKa6p9Hbea5sgOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmRsw4e2pu9N69e8N6ahx9+vTppbXUXHgMLXX77wsuuCCsp/Z7tEz3nj17wrZVl2yuY756Ckd2IBOEHcgEYQcyQdiBTBB2IBOEHcgEYQcyMWLG2VNWrlwZ1mfPnh3WN2zYUFpLjRdjaKmx6FYuhZ2aT151nLyO+eopySO7mU02sz+b2VYz22Jmvy62n2Fmr5nZB8Xn+E4CAGo1nNP4w5L+xd1/IelSSXeZ2S8kPSDpdXefKun14nsAHSoZdnff5e7vFF/vl/SupEmS5kpaXvzYckk3tqqTAKr7Sa/ZzewcSTMkrZU0wd13FaXPJE0oabNQ0sLGuwigGYb9bryZnSLpBUmL3P2YGQY+8E7JkO+WuPtSd5/p7jMr9RRAJcMKu5mdpIGg/8HdVxSbd5vZxKI+UVJfa7oIoBmSp/E2MAaxTNK77r5kUKlH0gJJjxWfX25JD4cpNd3x+eefD+s9PT1hPRpKSU2HRGNmzZoV1seOHRvW+/rKjz9Vbg0uVb+9d3Sr6VYN2w3nNfsVkv5R0iYzOzrY/KAGQv5HM7td0seSbm5JDwE0RTLs7v6mpLIrDK5qbncAtAqXywKZIOxAJgg7kAnCDmSCsAOZGDFTXKtOM01Np0TzpcbJx4wZE9ZT01Cj9l1dXWHbVi+TzZLNAFqGsAOZIOxAJgg7kAnCDmSCsAOZIOxAJkbMODs6UzQWnrq2YcmSJWE91X7NmjWlta1bt4ZtRyKO7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZMJaPW/3mCcza9+ToSNUWfo4ure6JI0ePTqsHzx4sLSW+rtvZy6azd2H3Okc2YFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyMRw1mefLOn3kiZIcklL3f2/zOxhSf8saU/xow+6+6pWdRT5SY3RR+Pow2kfOZ7H2cskL6oxs4mSJrr7O2b2M0lvS7pRA+uxf+3u/zHsJ+OimuxUCdyoUaPCemqhhei5U3/3dSzi0CxlF9UMZ332XZJ2FV/vN7N3JU1qbvcAtNpPes1uZudImiFpbbHpbjPbaGZPm9m4kjYLzWy9ma2v1FMAlQz72ngzO0XS/0pa7O4rzGyCpL0aeB3/iAZO9f8p8RicxmeG0/j2q3RtvJmdJOkFSX9w9xXFA+529yPu/p2k30q6pFmdBdB8ybDbwH+PyyS96+5LBm2fOOjHfilpc/O7B6BZhvNu/CxJb0jaJOnouc2DkuZLmq6B0/heSb8q3syLHovTeKDFyk7jmc8OjDDMZwcyR9iBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHcgEYQcyQdiBTCRvONlkeyV9POj78cW2TtSpfevUfkn0rVHN7NvflBXaOp/9R09utt7dZ9bWgUCn9q1T+yXRt0a1q2+cxgOZIOxAJuoO+9Kanz/SqX3r1H5J9K1Rbelbra/ZAbRP3Ud2AG1C2IFM1BJ2M7vOzLaZ2XYze6COPpQxs14z22RmG+pen65YQ6/PzDYP2naGmb1mZh8Un4dcY6+mvj1sZjuLfbfBzObU1LfJZvZnM9tqZlvM7NfF9lr3XdCvtuy3tr9mN7NRkt6XdLWkHZLWSZrv7lvb2pESZtYraaa7134Bhpn9vaSvJf3e3acV2/5d0j53f6z4j3Kcu/9rh/TtYf3EZbxb1LeyZcZvU437rpnLnzeijiP7JZK2u/tH7t4v6TlJc2voR8dz9zWS9v1g81xJy4uvl2vgj6XtSvrWEdx9l7u/U3y9X9LRZcZr3XdBv9qijrBPkvSXQd/vUGet9+6SXjWzt81sYd2dGcKEQctsfSZpQp2dGUJyGe92+sEy4x2z7xpZ/rwq3qD7sVnu/neS/kHSXcXpakfygddgnTR2+htJP9fAGoC7JD1eZ2eKZcZfkLTI3b8aXKtz3w3Rr7bstzrCvlPS5EHfn1Vs6wjuvrP43CfpRXXeUtS7j66gW3zuq7k/3+ukZbyHWmZcHbDv6lz+vI6wr5M01czONbMuSfMk9dTQjx8xs+7ijROZWbeka9R5S1H3SFpQfL1A0ss19uUYnbKMd9ky46p539W+/Lm7t/1D0hwNvCP/oaR/q6MPJf2aIun/io8tdfdN0rMaOK07pIH3Nm6X9FeSXpf0gaT/kXRGB/XtGQ0s7b1RA8GaWFPfZmngFH2jpA3Fx5y6913Qr7bsNy6XBTLBG3RAJgg7kAnCDmSCsAOZIOxAJgg7kAnCDmTi/wG50P5CE6qH/wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "HomNeJp3Q-w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"/content/drive/MyDrive/Character Recognition/modelccn_1\")"
      ],
      "metadata": {
        "id": "MNU883uvFIsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = keras.models.load_model(\"/content/drive/MyDrive/Character Recognition/modelccn\")"
      ],
      "metadata": {
        "id": "MCABwwGomVkO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kW7eOvrY9he_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "nuAQlfcDRBF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "7blScgNUPK1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pickel Dump\n",
        "with open('/content/drive/MyDrive/Character Recognition/data.pkl', 'wb') as f:\n",
        "  pickle.dump(data, f)\n",
        "with open('/content/drive/MyDrive/Character Recognition/labels.pkl', 'wb') as f:\n",
        "  pickle.dump(labels, f)"
      ],
      "metadata": {
        "id": "eWKKxtbuQzJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pickel Load\n",
        "with open('/content/drive/MyDrive/Character Recognition/data.pkl', 'rb') as f:\n",
        "  data = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Character Recognition/labels.pkl', 'rb') as f:\n",
        "  labels = pickle.load(f)"
      ],
      "metadata": {
        "id": "Ib8zdVCQQ1LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "7-mbiEdnRCnP"
      }
    }
  ]
}